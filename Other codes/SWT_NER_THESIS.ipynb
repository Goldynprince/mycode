{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = r\"C:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\workspace\\ner\\ner-1\\ner\\data\\swt\\processed\\swt_splitted_records_methods_with_annos.json\"\n",
    "folder_path = r\"C:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\mycode\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def zerolistmaker(n):\n",
    "    listofzeros = [0] * n\n",
    "    return listofzeros\n",
    "\n",
    "def clean_text(string): \n",
    "\n",
    "    # punc = '''\n",
    "    # !\"();:',.<>\\/?@*+_[]=\n",
    "    # '''\n",
    "    punc = '''\n",
    "    !\"();:',.<>\\/?@*+_[]=\n",
    "    '''\n",
    "    for ele in string: \n",
    "        if ele == '’':\n",
    "            string = string.replace(ele, \"\").strip() \n",
    "\n",
    "        elif ele in punc: \n",
    "            string = string.replace(ele, \" \").strip()\n",
    "        \n",
    "    \n",
    "    return string\n",
    "\n",
    "def clean_string(input_string):\n",
    "    cleaned_string = clean_text(input_string)\n",
    "\n",
    "    # Define the regular expression pattern to match square brackets with any digit inside\n",
    "    square_bracket_pattern = r'\\[\\d]'\n",
    "    cleaned_string = re.sub(square_bracket_pattern, '', cleaned_string)\n",
    "\n",
    "    # Define the regular expression pattern to match square brackets with any double digit inside\n",
    "    square_bracket_pattern = r'\\[\\d\\d]'\n",
    "    cleaned_string = re.sub(square_bracket_pattern, '', cleaned_string)\n",
    "\n",
    "     # Use the `replace()` method to replace double spaces with a single space\n",
    "    cleaned_string = cleaned_string.replace('  ', ' ')\n",
    "\n",
    "    return cleaned_string\n",
    "\n",
    "# def clean_annotation(anno_dict):######\n",
    "#     condition = anno_dict['condition']\n",
    "#     design = anno_dict['design_1'] + ' ' + anno_dict['design_2'] \n",
    "#     group_A = anno_dict['group_A_1'] + ' ' + anno_dict['group_A_2'] \n",
    "#     group_B = anno_dict['group_B_1'] + ' ' + anno_dict['group_B_2'] \n",
    "#     group_C = anno_dict['group_C_1'] + ' ' + anno_dict['group_C_2'] \n",
    "#     group_D = anno_dict['group_D_1'] + ' ' + anno_dict['group_D_2'] \n",
    "#     N_A = anno_dict['N_A']\n",
    "#     N_B = anno_dict['N_B']\n",
    "#     N_C = anno_dict['N_C']\n",
    "#     N_D = anno_dict['N_D']\n",
    "#     return {'condition':condition, 'design': design, 'group_A':group_A, 'group_B':group_B, 'group_C':group_C, 'group_D':group_D,\n",
    "#             'N_A':N_A, 'N_B':N_B, 'N_C':N_C, 'N_D':N_D}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Gbadamosi\\\\Documents\\\\Nerd Corner\\\\Master in ds and AI\\\\MSC project\\\\workspace\\\\workspace\\\\ner\\\\ner-1\\\\ner\\\\data\\\\swt\\\\processed\\\\swt_splitted_records_methods_with_annos.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\mycode\\SWT_NER_THESIS.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Gbadamosi/Documents/Nerd%20Corner/Master%20in%20ds%20and%20AI/MSC%20project/workspace/personal_workspace/mycode/SWT_NER_THESIS.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Gbadamosi/Documents/Nerd%20Corner/Master%20in%20ds%20and%20AI/MSC%20project/workspace/personal_workspace/mycode/SWT_NER_THESIS.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(doc_path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Gbadamosi/Documents/Nerd%20Corner/Master%20in%20ds%20and%20AI/MSC%20project/workspace/personal_workspace/mycode/SWT_NER_THESIS.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     doc \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Gbadamosi/Documents/Nerd%20Corner/Master%20in%20ds%20and%20AI/MSC%20project/workspace/personal_workspace/mycode/SWT_NER_THESIS.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m doc[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m     )\n\u001b[1;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Gbadamosi\\\\Documents\\\\Nerd Corner\\\\Master in ds and AI\\\\MSC project\\\\workspace\\\\workspace\\\\ner\\\\ner-1\\\\ner\\\\data\\\\swt\\\\processed\\\\swt_splitted_records_methods_with_annos.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(doc_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    doc = json.load(f)\n",
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4275"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'condition': 1,\n",
    " 'design': 2,\n",
    " 'group_A': 3,\n",
    " 'group_B': 4,\n",
    " 'group_C': 5,\n",
    " 'group_D': 6,\n",
    " 'N_A': 7,\n",
    " 'N_B': 8,\n",
    " 'N_C': 9,\n",
    " 'N_D': 10}\n",
    "\n",
    "record_dict = []\n",
    "checklist = []\n",
    "\n",
    "for document in doc: \n",
    "    \n",
    "\n",
    "    #get pmid for the document\n",
    "    pmid = document['pmid']\n",
    "\n",
    "    #remove punctuation marks and reference the annotation in the document\n",
    "    try:\n",
    "        result = clean_annotation(document['annotations'])\n",
    "    except KeyError: \n",
    "        pass\n",
    "\n",
    "    # get the text of the document(could be abstract, abstract + mehtod, or splitted abstract + method)\n",
    "    text = clean_string(document['text']).lower()\n",
    "    split_text = text.split()\n",
    "\n",
    "    # get empty labels for the len of the document\n",
    "    labels_list  = zerolistmaker(len(split_text))\n",
    "    # print(len(labels_list), len(split_text))\n",
    "\n",
    "    # get all the annotations in the document clean it and split into words\n",
    "    for anno_class in result.keys():\n",
    "        \n",
    "        annotation = result[anno_class]\n",
    "        annotation = clean_string(annotation).lower()\n",
    "        \n",
    "        temp = annotation.split()\n",
    "        # find index of words in text and assign a label \n",
    "        for val in temp: \n",
    "            if val in split_text:\n",
    "                index = split_text.index(val) \n",
    "                labels_list[index] = label_dict[anno_class]\n",
    "            else: \n",
    "                checklist.append([pmid, split_text, val])\n",
    "\n",
    "\n",
    "            # try: \n",
    "            #     index = split_text.index(val)\n",
    "            # except ValueError: \n",
    "            #     pass\n",
    "            # try: \n",
    "            #     labels_list[index] = label_dict[anno_class]\n",
    "            # except IndexError: \n",
    "            #     checklist.append([split_text, val])\n",
    "            #     print(len(labels_list), len(split_text), index)\n",
    "  \n",
    "    # create dictionary\n",
    "    temp_dict={'pmid':pmid,\n",
    "                        \"ner_tags\": labels_list,\n",
    "                        \"tokens\": split_text\n",
    "                        # \"merged_annotation\": result\n",
    "                    \n",
    "        }\n",
    "    record_dict.append(temp_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pmid': '16960863',\n",
       " 'ner_tags': [0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  4,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  9,\n",
       "  0,\n",
       "  0,\n",
       "  10,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'tokens': ['effects',\n",
       "  'of',\n",
       "  'rivastigmine',\n",
       "  'in',\n",
       "  'patients',\n",
       "  'with',\n",
       "  'and',\n",
       "  'without',\n",
       "  'visual',\n",
       "  'hallucinations',\n",
       "  'in',\n",
       "  'dementia',\n",
       "  'associated',\n",
       "  'with',\n",
       "  'parkinsons',\n",
       "  'disease',\n",
       "  'we',\n",
       "  'aimed',\n",
       "  'to',\n",
       "  'determine',\n",
       "  'prospectively',\n",
       "  'whether',\n",
       "  'rivastigmine',\n",
       "  'an',\n",
       "  'inhibitor',\n",
       "  'of',\n",
       "  'acetylcholinesterase',\n",
       "  'and',\n",
       "  'butyrylcholinesterase',\n",
       "  'provided',\n",
       "  'benefits',\n",
       "  'in',\n",
       "  'patients',\n",
       "  'with',\n",
       "  'and',\n",
       "  'without',\n",
       "  'visual',\n",
       "  'hallucinations',\n",
       "  'in',\n",
       "  'a',\n",
       "  'population',\n",
       "  'with',\n",
       "  'dementia',\n",
       "  'associated',\n",
       "  'with',\n",
       "  'parkinson',\n",
       "  's',\n",
       "  'disease',\n",
       "  'pdd',\n",
       "  'this',\n",
       "  'was',\n",
       "  'a',\n",
       "  '24-week',\n",
       "  'double-blind',\n",
       "  'placebo-controlled',\n",
       "  'study',\n",
       "  'primary',\n",
       "  'efficacy',\n",
       "  'measures',\n",
       "  'were',\n",
       "  'the',\n",
       "  'alzheimer',\n",
       "  's',\n",
       "  'disease',\n",
       "  'assessment',\n",
       "  'scale',\n",
       "  'cognitive',\n",
       "  'subscale',\n",
       "  'adas-cog',\n",
       "  'and',\n",
       "  'alzheimer',\n",
       "  's',\n",
       "  'disease',\n",
       "  'cooperative',\n",
       "  'study-clinician',\n",
       "  's',\n",
       "  'global',\n",
       "  'impression',\n",
       "  'of',\n",
       "  'change',\n",
       "  'adcs-cgic',\n",
       "  'secondary',\n",
       "  'efficacy',\n",
       "  'measures',\n",
       "  'included',\n",
       "  'activities',\n",
       "  'of',\n",
       "  'daily',\n",
       "  'living',\n",
       "  'behavioral',\n",
       "  'symptoms',\n",
       "  'and',\n",
       "  'executive',\n",
       "  'and',\n",
       "  'attentional',\n",
       "  'functions',\n",
       "  'patients',\n",
       "  'were',\n",
       "  'stratified',\n",
       "  'according',\n",
       "  'to',\n",
       "  'the',\n",
       "  'presence',\n",
       "  'of',\n",
       "  'visual',\n",
       "  'hallucinations',\n",
       "  'at',\n",
       "  'baseline',\n",
       "  'the',\n",
       "  'study',\n",
       "  'included',\n",
       "  '188',\n",
       "  'visual',\n",
       "  'hallucinators',\n",
       "  '118',\n",
       "  'on',\n",
       "  'rivastigmine',\n",
       "  '70',\n",
       "  'on',\n",
       "  'placebo',\n",
       "  'and',\n",
       "  '348',\n",
       "  'nonvisual',\n",
       "  'hallucinators',\n",
       "  '239',\n",
       "  'on',\n",
       "  'rivastigmine',\n",
       "  '109',\n",
       "  'on',\n",
       "  'placebo',\n",
       "  'rivastigmine',\n",
       "  'provided',\n",
       "  'benefits',\n",
       "  'in',\n",
       "  'both',\n",
       "  'visual',\n",
       "  'hallucinators',\n",
       "  'and',\n",
       "  'nonvisual',\n",
       "  'hallucinators',\n",
       "  'absolute',\n",
       "  'responses',\n",
       "  'to',\n",
       "  'rivastigmine',\n",
       "  'on',\n",
       "  'the',\n",
       "  'adas-cog',\n",
       "  'were',\n",
       "  'comparable',\n",
       "  'over',\n",
       "  '6',\n",
       "  'months',\n",
       "  'although',\n",
       "  'rivastigmine-placebo',\n",
       "  'differences',\n",
       "  'tended',\n",
       "  'to',\n",
       "  'be',\n",
       "  'larger',\n",
       "  'in',\n",
       "  'visual',\n",
       "  'hallucinators',\n",
       "  '4',\n",
       "  '27',\n",
       "  'p',\n",
       "  '0',\n",
       "  '002',\n",
       "  'than',\n",
       "  'in',\n",
       "  'nonhallucinators',\n",
       "  '2',\n",
       "  '09',\n",
       "  'p',\n",
       "  '0',\n",
       "  '015',\n",
       "  'on',\n",
       "  'the',\n",
       "  'adcs-cgic',\n",
       "  'differences',\n",
       "  'between',\n",
       "  'rivastigmine',\n",
       "  'and',\n",
       "  'placebo',\n",
       "  'were',\n",
       "  '0',\n",
       "  '5',\n",
       "  'in',\n",
       "  'visual',\n",
       "  'hallucinators',\n",
       "  'p',\n",
       "  '0',\n",
       "  '030',\n",
       "  'and',\n",
       "  '0',\n",
       "  '3',\n",
       "  'in',\n",
       "  'nonhallucinators',\n",
       "  'p',\n",
       "  '0',\n",
       "  '111',\n",
       "  'rivastigmine',\n",
       "  'provided',\n",
       "  'benefits',\n",
       "  'on',\n",
       "  'all',\n",
       "  'secondary',\n",
       "  'efficacy',\n",
       "  'measures',\n",
       "  'and',\n",
       "  'placebo',\n",
       "  'declines',\n",
       "  'and',\n",
       "  'treatment',\n",
       "  'differences',\n",
       "  'were',\n",
       "  'more',\n",
       "  'marked',\n",
       "  'in',\n",
       "  'visual',\n",
       "  'hallucinators',\n",
       "  'adverse',\n",
       "  'events',\n",
       "  'were',\n",
       "  'reported',\n",
       "  'more',\n",
       "  'frequently',\n",
       "  'by',\n",
       "  'rivastigmine-treated',\n",
       "  'patients',\n",
       "  'although',\n",
       "  'this',\n",
       "  'difference',\n",
       "  'was',\n",
       "  'less',\n",
       "  'marked',\n",
       "  'in',\n",
       "  'visual',\n",
       "  'hallucinators',\n",
       "  'visual',\n",
       "  'hallucinations',\n",
       "  'appear',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'more',\n",
       "  'rapid',\n",
       "  'decline',\n",
       "  'and',\n",
       "  'possibly',\n",
       "  'greater',\n",
       "  'therapeutic',\n",
       "  'benefit',\n",
       "  'from',\n",
       "  'rivastigmine',\n",
       "  'treatment',\n",
       "  'in',\n",
       "  'pdd',\n",
       "  'patients',\n",
       "  'and',\n",
       "  'methods',\n",
       "  'study',\n",
       "  'design',\n",
       "  'the',\n",
       "  'methodology',\n",
       "  'of',\n",
       "  'the',\n",
       "  'double-blind',\n",
       "  'study',\n",
       "  'has',\n",
       "  'been',\n",
       "  'described',\n",
       "  'previously',\n",
       "  '11',\n",
       "  'patients',\n",
       "  'had',\n",
       "  'a',\n",
       "  'diagnosis',\n",
       "  'of',\n",
       "  'pd',\n",
       "  'according',\n",
       "  'to',\n",
       "  'the',\n",
       "  'queens',\n",
       "  'square',\n",
       "  'brain',\n",
       "  'bank',\n",
       "  'clinical',\n",
       "  'diagnostic',\n",
       "  'criteria12',\n",
       "  'and',\n",
       "  'dementia',\n",
       "  'due',\n",
       "  'to',\n",
       "  'pd',\n",
       "  'according',\n",
       "  'to',\n",
       "  'the',\n",
       "  'fourth',\n",
       "  'edition',\n",
       "  'of',\n",
       "  'the',\n",
       "  'diagnostic',\n",
       "  'and',\n",
       "  'statistical',\n",
       "  'manual',\n",
       "  'of',\n",
       "  'mental',\n",
       "  'disorders',\n",
       "  'dsm-iv',\n",
       "  'code',\n",
       "  '294',\n",
       "  '1',\n",
       "  '13',\n",
       "  'patients',\n",
       "  'had',\n",
       "  'mild',\n",
       "  'to',\n",
       "  'moderately',\n",
       "  'severe',\n",
       "  'dementia',\n",
       "  'as',\n",
       "  'defined',\n",
       "  'by',\n",
       "  'a',\n",
       "  'mini-mental',\n",
       "  'state',\n",
       "  'examination',\n",
       "  'mmse',\n",
       "  'score',\n",
       "  'of',\n",
       "  '10',\n",
       "  'to',\n",
       "  '24',\n",
       "  'patients',\n",
       "  'were',\n",
       "  'randomized',\n",
       "  'to',\n",
       "  'rivastigmine',\n",
       "  'or',\n",
       "  'placebo',\n",
       "  'in',\n",
       "  'a',\n",
       "  '2',\n",
       "  '1',\n",
       "  'ratio',\n",
       "  'which',\n",
       "  'permitted',\n",
       "  'the',\n",
       "  'collection',\n",
       "  'of',\n",
       "  'more',\n",
       "  'safety',\n",
       "  'data',\n",
       "  'in',\n",
       "  'the',\n",
       "  'rivastigmine',\n",
       "  'group',\n",
       "  'the',\n",
       "  'study',\n",
       "  'included',\n",
       "  'a',\n",
       "  '16-week',\n",
       "  'dose',\n",
       "  'escalation',\n",
       "  'phase',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'reach',\n",
       "  'maximum',\n",
       "  'tolerated',\n",
       "  'doses',\n",
       "  'of',\n",
       "  'rivastigmine',\n",
       "  'up',\n",
       "  'to',\n",
       "  '12',\n",
       "  'mg',\n",
       "  'day',\n",
       "  'which',\n",
       "  'was',\n",
       "  'maintained',\n",
       "  'for',\n",
       "  'another',\n",
       "  '8',\n",
       "  'weeks',\n",
       "  'at',\n",
       "  'baseline',\n",
       "  'and',\n",
       "  'at',\n",
       "  'weeks',\n",
       "  '16',\n",
       "  'and',\n",
       "  '24',\n",
       "  'efficacy',\n",
       "  'measures',\n",
       "  'were',\n",
       "  'performed',\n",
       "  'primary',\n",
       "  'measures',\n",
       "  'were',\n",
       "  'the',\n",
       "  'cognitive',\n",
       "  'subscale',\n",
       "  'of',\n",
       "  'the',\n",
       "  'alzheimers',\n",
       "  'disease',\n",
       "  'assessment',\n",
       "  'scale',\n",
       "  'adas-cog',\n",
       "  '14',\n",
       "  'and',\n",
       "  'the',\n",
       "  'alzheimers',\n",
       "  'disease',\n",
       "  'cooperative',\n",
       "  'study-clinicians',\n",
       "  'global',\n",
       "  'impression',\n",
       "  'of',\n",
       "  'change',\n",
       "  'adcscgic',\n",
       "  '15',\n",
       "  'secondary',\n",
       "  'efficacy',\n",
       "  'parameters',\n",
       "  'were',\n",
       "  'the',\n",
       "  'alzheimers',\n",
       "  'disease',\n",
       "  'cooperative',\n",
       "  'study-activities',\n",
       "  'of',\n",
       "  'daily',\n",
       "  'living',\n",
       "  'adcs-adl',\n",
       "  '16',\n",
       "  'verbal',\n",
       "  'fluency',\n",
       "  'tests',\n",
       "  'from',\n",
       "  'the',\n",
       "  'delis-kaplan',\n",
       "  'executive',\n",
       "  'function',\n",
       "  'system',\n",
       "  'd-kefs',\n",
       "  '17',\n",
       "  'power',\n",
       "  'of',\n",
       "  'attention',\n",
       "  'including',\n",
       "  'choice',\n",
       "  'reaction',\n",
       "  'time',\n",
       "  'crt',\n",
       "  'from',\n",
       "  'the',\n",
       "  'cognitive',\n",
       "  'drug',\n",
       "  'research',\n",
       "  'cdr',\n",
       "  'attention',\n",
       "  'battery',\n",
       "  '18',\n",
       "  'the',\n",
       "  'mmse',\n",
       "  '19',\n",
       "  'and',\n",
       "  'the',\n",
       "  '10-item',\n",
       "  'neuropsychiatric',\n",
       "  'inventory',\n",
       "  'npi-10',\n",
       "  '20',\n",
       "  'safety',\n",
       "  'evaluations',\n",
       "  'included',\n",
       "  'recording',\n",
       "  'adverse',\n",
       "  'events',\n",
       "  'laboratory',\n",
       "  'parameters',\n",
       "  'and',\n",
       "  'ecg',\n",
       "  'extrapyramidal',\n",
       "  'signs',\n",
       "  'were',\n",
       "  'assessed',\n",
       "  'with',\n",
       "  'the',\n",
       "  'motor',\n",
       "  'subsection',\n",
       "  'of',\n",
       "  'the',\n",
       "  'unified',\n",
       "  'parkinsons',\n",
       "  'disease',\n",
       "  'rating',\n",
       "  'scale',\n",
       "  'updrs',\n",
       "  'part',\n",
       "  'iii',\n",
       "  '21',\n",
       "  'the',\n",
       "  'protocol',\n",
       "  'informed',\n",
       "  'consent',\n",
       "  'form',\n",
       "  'and',\n",
       "  'information',\n",
       "  'to',\n",
       "  'patients',\n",
       "  'and',\n",
       "  'caregivers',\n",
       "  'were',\n",
       "  'reviewed',\n",
       "  'by',\n",
       "  'local',\n",
       "  'institutional',\n",
       "  'review']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['16960863',\n",
       " ['boards',\n",
       "  'all',\n",
       "  'procedures',\n",
       "  'were',\n",
       "  'in',\n",
       "  'accordance',\n",
       "  'with',\n",
       "  'the',\n",
       "  'helsinki',\n",
       "  'declaration',\n",
       "  'as',\n",
       "  'revised',\n",
       "  'in',\n",
       "  '1983',\n",
       "  'analyses',\n",
       "  'of',\n",
       "  'response',\n",
       "  'in',\n",
       "  'visual',\n",
       "  'hallucinators',\n",
       "  'vs',\n",
       "  'nonhallucinators',\n",
       "  'this',\n",
       "  'was',\n",
       "  'a',\n",
       "  'prospective',\n",
       "  'analysis',\n",
       "  'that',\n",
       "  'was',\n",
       "  'described',\n",
       "  'in',\n",
       "  'the',\n",
       "  'protocol',\n",
       "  'the',\n",
       "  'presence',\n",
       "  'or',\n",
       "  'absence',\n",
       "  'of',\n",
       "  'any',\n",
       "  'hallucinations',\n",
       "  'at',\n",
       "  'baseline',\n",
       "  'was',\n",
       "  'recorded',\n",
       "  'using',\n",
       "  'the',\n",
       "  'npi-10',\n",
       "  'caregivers',\n",
       "  'were',\n",
       "  'asked',\n",
       "  'to',\n",
       "  'tick',\n",
       "  'an',\n",
       "  'extra',\n",
       "  'box',\n",
       "  'marking',\n",
       "  'the',\n",
       "  'presence',\n",
       "  'of',\n",
       "  'visual',\n",
       "  'hallucinations',\n",
       "  'two',\n",
       "  'subgroups',\n",
       "  'were',\n",
       "  'defined',\n",
       "  'those',\n",
       "  'with',\n",
       "  'visual',\n",
       "  'hallucinations',\n",
       "  'and',\n",
       "  'those',\n",
       "  'without',\n",
       "  'visual',\n",
       "  'hallucinations',\n",
       "  'but',\n",
       "  'who',\n",
       "  'might',\n",
       "  'have',\n",
       "  'other',\n",
       "  'kinds',\n",
       "  'of',\n",
       "  'hallucination',\n",
       "  'at',\n",
       "  'baseline',\n",
       "  'all',\n",
       "  'patients',\n",
       "  'who',\n",
       "  'received',\n",
       "  'at',\n",
       "  'least',\n",
       "  'one',\n",
       "  'dose',\n",
       "  'of',\n",
       "  'study',\n",
       "  'medication',\n",
       "  'and',\n",
       "  'had',\n",
       "  'at',\n",
       "  'least',\n",
       "  'one',\n",
       "  'safety',\n",
       "  'measurement',\n",
       "  'after',\n",
       "  'baseline',\n",
       "  'were',\n",
       "  'included',\n",
       "  'in',\n",
       "  'safety',\n",
       "  'analyses',\n",
       "  'main',\n",
       "  'efficacy',\n",
       "  'analyses',\n",
       "  'were',\n",
       "  'based',\n",
       "  'on',\n",
       "  'an',\n",
       "  'intention-to-treat',\n",
       "  'and',\n",
       "  'retrieved',\n",
       "  'dropout',\n",
       "  'itt',\n",
       "  'rdo',\n",
       "  'population',\n",
       "  'defined',\n",
       "  'as',\n",
       "  'all',\n",
       "  'randomized',\n",
       "  'patients',\n",
       "  'who',\n",
       "  'received',\n",
       "  'at',\n",
       "  'least',\n",
       "  'one',\n",
       "  'dose',\n",
       "  'of',\n",
       "  'study',\n",
       "  'medication',\n",
       "  'and',\n",
       "  'had',\n",
       "  'a',\n",
       "  'least',\n",
       "  'one',\n",
       "  'assessment',\n",
       "  'on',\n",
       "  'study',\n",
       "  'drug',\n",
       "  'for',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'primary',\n",
       "  'efficacy',\n",
       "  'variables',\n",
       "  'itt',\n",
       "  'and',\n",
       "  'the',\n",
       "  'patients',\n",
       "  'who',\n",
       "  'discontinued',\n",
       "  'early',\n",
       "  'and',\n",
       "  'continued',\n",
       "  'to',\n",
       "  'attend',\n",
       "  'original',\n",
       "  'scheduled',\n",
       "  'visits',\n",
       "  'for',\n",
       "  'efficacy',\n",
       "  'evaluations',\n",
       "  'rdo',\n",
       "  'supportive',\n",
       "  'analyses',\n",
       "  'included',\n",
       "  'last',\n",
       "  'observation',\n",
       "  'carried',\n",
       "  'forward',\n",
       "  'locf',\n",
       "  'as',\n",
       "  'for',\n",
       "  'the',\n",
       "  'itt',\n",
       "  'rdo',\n",
       "  'but',\n",
       "  'with',\n",
       "  'an',\n",
       "  'locf',\n",
       "  'imputation',\n",
       "  'and',\n",
       "  'observed',\n",
       "  'case',\n",
       "  'oc',\n",
       "  'no',\n",
       "  'imputation',\n",
       "  'populations',\n",
       "  'changes',\n",
       "  'from',\n",
       "  'baseline',\n",
       "  'on',\n",
       "  'the',\n",
       "  'adas-cog',\n",
       "  'adcsadl',\n",
       "  'cdr',\n",
       "  'and',\n",
       "  'npi-10',\n",
       "  'were',\n",
       "  'analyzed',\n",
       "  'using',\n",
       "  'an',\n",
       "  'analysis',\n",
       "  'of',\n",
       "  'covariance',\n",
       "  'ancova',\n",
       "  'model',\n",
       "  'using',\n",
       "  'treatment',\n",
       "  'and',\n",
       "  'country',\n",
       "  'as',\n",
       "  'factors',\n",
       "  'and',\n",
       "  'baseline',\n",
       "  'scores',\n",
       "  'as',\n",
       "  'covariates',\n",
       "  'adcs-cgic',\n",
       "  'mmse',\n",
       "  'and',\n",
       "  'd-kefs',\n",
       "  'scores',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'changes',\n",
       "  'on',\n",
       "  'individual',\n",
       "  'items',\n",
       "  'on',\n",
       "  'the',\n",
       "  'npi',\n",
       "  'were',\n",
       "  'analyzed',\n",
       "  'using',\n",
       "  'the',\n",
       "  'van',\n",
       "  'elteren',\n",
       "  'test',\n",
       "  'controlling',\n",
       "  'for',\n",
       "  'country',\n",
       "  'using',\n",
       "  'the',\n",
       "  'cdr',\n",
       "  'a',\n",
       "  'composite',\n",
       "  'power',\n",
       "  'of',\n",
       "  'attention',\n",
       "  'score',\n",
       "  'was',\n",
       "  'defined',\n",
       "  'that',\n",
       "  'reflected',\n",
       "  'in',\n",
       "  'everyday',\n",
       "  'terms',\n",
       "  '“effortful',\n",
       "  'concentration',\n",
       "  '”',\n",
       "  'percentages',\n",
       "  'of',\n",
       "  'patients',\n",
       "  'changing',\n",
       "  'increasing',\n",
       "  'or',\n",
       "  'decreasing',\n",
       "  'dosage',\n",
       "  'or',\n",
       "  'initiating',\n",
       "  'use',\n",
       "  'dopaminergic',\n",
       "  'medication',\n",
       "  'use',\n",
       "  'over',\n",
       "  'the',\n",
       "  'course',\n",
       "  'of',\n",
       "  'the',\n",
       "  'study',\n",
       "  'were',\n",
       "  'recorded',\n",
       "  'to',\n",
       "  'compare',\n",
       "  'medications',\n",
       "  'with',\n",
       "  'different',\n",
       "  'potencies',\n",
       "  'in',\n",
       "  'the',\n",
       "  'dopamine',\n",
       "  'agonist',\n",
       "  'category',\n",
       "  'the',\n",
       "  'daily',\n",
       "  'dose',\n",
       "  'of',\n",
       "  'each',\n",
       "  'one',\n",
       "  'was',\n",
       "  'converted',\n",
       "  'into',\n",
       "  'the',\n",
       "  'equivalent',\n",
       "  'pramipexole',\n",
       "  'dosage',\n",
       "  'based',\n",
       "  'on',\n",
       "  'midpoints',\n",
       "  'of',\n",
       "  'recommended',\n",
       "  'average',\n",
       "  'dosages',\n",
       "  'reported',\n",
       "  'in',\n",
       "  'the',\n",
       "  'literature',\n",
       "  'for',\n",
       "  'example',\n",
       "  '2',\n",
       "  '75',\n",
       "  'mg',\n",
       "  'day',\n",
       "  'of',\n",
       "  'pergolide',\n",
       "  'range',\n",
       "  '2-3',\n",
       "  '5',\n",
       "  'mg',\n",
       "  'day',\n",
       "  'was',\n",
       "  'considered',\n",
       "  'equivalent',\n",
       "  'to',\n",
       "  '3',\n",
       "  'mg',\n",
       "  'day',\n",
       "  'of',\n",
       "  'pramipexole',\n",
       "  'range',\n",
       "  '1',\n",
       "  '5-',\n",
       "  '4',\n",
       "  '5',\n",
       "  'mg',\n",
       "  'day',\n",
       "  'which',\n",
       "  'resulted',\n",
       "  'in',\n",
       "  'a',\n",
       "  'conversion',\n",
       "  'factor',\n",
       "  'of',\n",
       "  '3',\n",
       "  '2',\n",
       "  '75',\n",
       "  'thus',\n",
       "  'if',\n",
       "  'a',\n",
       "  'patient',\n",
       "  'received',\n",
       "  '5',\n",
       "  '5',\n",
       "  'mg',\n",
       "  'day',\n",
       "  'of',\n",
       "  'pergolide',\n",
       "  'it',\n",
       "  'was',\n",
       "  'considered',\n",
       "  'to',\n",
       "  'be',\n",
       "  'the',\n",
       "  'equivalent',\n",
       "  'of',\n",
       "  'taking',\n",
       "  '6',\n",
       "  'mg',\n",
       "  'day',\n",
       "  'of',\n",
       "  'pramipexole',\n",
       "  'this',\n",
       "  'is',\n",
       "  'considered',\n",
       "  'a',\n",
       "  'valid',\n",
       "  'approach',\n",
       "  'for',\n",
       "  'comparing',\n",
       "  'dosages',\n",
       "  'of',\n",
       "  'medications',\n",
       "  'with',\n",
       "  'different',\n",
       "  'potencies'],\n",
       " 'associated']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words in annotation which arent present in the text file\n",
    "checklist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path = os.path.join(folder_path, \"edited_swt_method_abstract_splitted.json\")\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(record_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4275"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(record_dict)\n",
    "# record_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e707a1d0c904452fade4cd552171c949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/4275 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "tru_label = ['O',\n",
    "            'condition',\n",
    "            'design',\n",
    "            'group_A',\n",
    "            'group_B',\n",
    "            'group_C',\n",
    "            'group_D',\n",
    "            'N_A',\n",
    "            'N_B',\n",
    "            'N_C',\n",
    "            'N_D']\n",
    "\n",
    "partcipant_ds = create_datasets(record_dict, tru_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pmid': Value(dtype='string', id=None),\n",
       " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'condition', 'design', 'group_A', 'group_B', 'group_C', 'group_D', 'N_A', 'N_B', 'N_C', 'N_D'], id=None), length=-1, id=None),\n",
       " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partcipant_ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"ncbi_disease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetDict' object has no attribute 'train_test_split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\mycode\\SWT_NER_THESIS.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Gbadamosi/Documents/Nerd%20Corner/Master%20in%20ds%20and%20AI/MSC%20project/workspace/personal_workspace/mycode/SWT_NER_THESIS.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Gbadamosi/Documents/Nerd%20Corner/Master%20in%20ds%20and%20AI/MSC%20project/workspace/personal_workspace/mycode/SWT_NER_THESIS.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m partcipant_ds \u001b[39m=\u001b[39m dataset\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Gbadamosi/Documents/Nerd%20Corner/Master%20in%20ds%20and%20AI/MSC%20project/workspace/personal_workspace/mycode/SWT_NER_THESIS.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m part_train_test \u001b[39m=\u001b[39m train_test_split(partcipant_ds, train_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, validation_size\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m) \n",
      "File \u001b[1;32mc:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\mycode\\preprocessing.py:140\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(data_set, train_test_size, validation_size)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_test_split\u001b[39m(data_set, train_test_size, validation_size):\n\u001b[0;32m    139\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m DatasetDict\n\u001b[1;32m--> 140\u001b[0m     train_testvalid \u001b[39m=\u001b[39m data_set\u001b[39m.\u001b[39;49mtrain_test_split(test_size\u001b[39m=\u001b[39mtrain_test_size)\n\u001b[0;32m    142\u001b[0m     \u001b[39m# Split the test to half test, half valid\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     test_valid \u001b[39m=\u001b[39m train_testvalid[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtrain_test_split(test_size\u001b[39m=\u001b[39mvalidation_size)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DatasetDict' object has no attribute 'train_test_split'"
     ]
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "partcipant_ds = dataset\n",
    "part_train_test = train_test_split(partcipant_ds, train_test_size=0.1, validation_size=0.5) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['pmid', 'ner_tags', 'tokens'],\n",
       "        num_rows: 3847\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['pmid', 'ner_tags', 'tokens'],\n",
       "        num_rows: 214\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['pmid', 'ner_tags', 'tokens'],\n",
       "        num_rows: 214\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "from transformers import ElectraForPreTraining, AutoTokenizer, DataCollatorForTokenClassification, AutoModelForTokenClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"kamalkraj/BioELECTRA-PICO\", model_max_length = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_align_labels(example, label_all_tokens = True):\n",
    "    # tokenized_input = tokenizer(example['tokens'], truncation = True, is_split_into_words=True, max_length = 450)\n",
    "    tokenized_input = tokenizer(example['tokens'], truncation = True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i , label in enumerate(example['ner_tags']):\n",
    "        word_ids = tokenized_input.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None: \n",
    "                label_ids.append(-100)\n",
    "            elif word_ids!= previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else: \n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100) \n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_input['labels'] = labels\n",
    "    return tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0d912e74084687b46b14677373f3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2844e5c2fe47158b366e3e004fc21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcccab480ea14115a4d300da320c1426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = part_train_test.map(tokenize_align_labels, batched = True, remove_columns=part_train_test['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_list = part_train_test['train'].features['ner_tags'].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i:label for i, label in enumerate(dis_list) }\n",
    "label2id = {label:i for i, label in enumerate(dis_list) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'condition',\n",
       " 2: 'design',\n",
       " 3: 'group_A',\n",
       " 4: 'group_B',\n",
       " 5: 'group_C',\n",
       " 6: 'group_D',\n",
       " 7: 'N_A',\n",
       " 8: 'N_B',\n",
       " 9: 'N_C',\n",
       " 10: 'N_D'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at kamalkraj/BioELECTRA-PICO and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([4, 768]) in the checkpoint and torch.Size([11, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([4]) in the checkpoint and torch.Size([11]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"kamalkraj/BioELECTRA-PICO\", ignore_mismatched_sizes=True, id2label = id2label )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    'test_swt_2.0',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_eval_batch_size=4,\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_strategy=\"epoch\",\n",
    "    # save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "metric = evaluate.load('seqeval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = part_train_test['train'].features['ner_tags'].feature.names\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    pred_logits, labels = eval_preds\n",
    "\n",
    "    pred_logits= np.argmax(pred_logits, axis = 2)\n",
    "\n",
    "    prediction = [\n",
    "                [label_list[eval_preds] for (eval_preds, l ) in zip(prediction, label) if l != -100 ] for prediction, label in zip(pred_logits, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "                [label_list[l] for (eval_preds, l ) in zip(prediction, label)  if l != -100 ] for prediction, label in zip(pred_logits, labels)] \n",
    "\n",
    "    results = metric.compute(predictions= prediction, references = true_labels)\n",
    "    return{\n",
    "    'precision':results['overall_precision'],\n",
    "    'recall':results['overall_recall'],\n",
    "    'f1':results['overall_f1'],\n",
    "    'accuracy':results['overall_accuracy']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model, \n",
    "    args,\n",
    "    train_dataset = tokenized_dataset['train'],\n",
    "    eval_dataset = tokenized_dataset['valid'],\n",
    "    data_collator = data_collator,\n",
    "    tokenizer = tokenizer,\n",
    "    compute_metrics = compute_metrics\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(28895, 768)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = zerolistmaker(len(split_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3847\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 214\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 214\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc2056bf4ae4228b2c9c76151b7b9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1459, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568855320562435285850253fb6ad52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: design seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_D seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: condition seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_A seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_B seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_B seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_D seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_A seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03765897825360298, 'eval_precision': 0.6146435452793835, 'eval_recall': 0.3556298773690078, 'eval_f1': 0.4505649717514124, 'eval_accuracy': 0.9911337302349401, 'eval_runtime': 54.3155, 'eval_samples_per_second': 3.94, 'eval_steps_per_second': 0.994, 'epoch': 1.0}\n",
      "{'loss': 0.0293, 'learning_rate': 1.1983333333333333e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff287dc99a1548a3b56b0db80e2d7d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: design seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_D seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: condition seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_A seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_B seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_B seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_D seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_A seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.02227335423231125, 'eval_precision': 0.7648546144121365, 'eval_recall': 0.6744704570791528, 'eval_f1': 0.716824644549763, 'eval_accuracy': 0.9946226233915882, 'eval_runtime': 37.1342, 'eval_samples_per_second': 5.763, 'eval_steps_per_second': 1.454, 'epoch': 2.0}\n",
      "{'loss': 0.0194, 'learning_rate': 7.983333333333334e-06, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e14f2331cf748ebab17acda1baf056c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: design seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_D seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: condition seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_A seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_B seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_B seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_D seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_A seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.018379075452685356, 'eval_precision': 0.7329192546583851, 'eval_recall': 0.7892976588628763, 'eval_f1': 0.7600644122383252, 'eval_accuracy': 0.9956362162046817, 'eval_runtime': 54.4279, 'eval_samples_per_second': 3.932, 'eval_steps_per_second': 0.992, 'epoch': 3.0}\n",
      "{'loss': 0.0157, 'learning_rate': 3.966666666666667e-06, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ee83aa82d142ab9f6371860f7865d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: design seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_D seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: condition seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_A seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_B seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_B seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_D seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_A seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.016115739941596985, 'eval_precision': 0.7727272727272727, 'eval_recall': 0.7959866220735786, 'eval_f1': 0.7841845140032949, 'eval_accuracy': 0.9961376779122122, 'eval_runtime': 37.9291, 'eval_samples_per_second': 5.642, 'eval_steps_per_second': 1.424, 'epoch': 4.0}\n",
      "{'loss': 0.0144, 'learning_rate': 0.0, 'epoch': 4.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee440617d104f4db7ffd68082457969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: design seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_D seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: condition seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_A seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_B seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_B seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_D seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_A seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.015791527926921844, 'eval_precision': 0.7775377969762419, 'eval_recall': 0.802675585284281, 'eval_f1': 0.7899067471201316, 'eval_accuracy': 0.9962977188827007, 'eval_runtime': 38.7358, 'eval_samples_per_second': 5.525, 'eval_steps_per_second': 1.394, 'epoch': 4.99}\n",
      "{'train_runtime': 30771.1247, 'train_samples_per_second': 0.625, 'train_steps_per_second': 0.039, 'train_loss': 0.04494851251443227, 'epoch': 4.99}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('SWT_tokenizer_2.0\\\\tokenizer_config.json',\n",
       " 'SWT_tokenizer_2.0\\\\special_tokens_map.json',\n",
       " 'SWT_tokenizer_2.0\\\\vocab.txt',\n",
       " 'SWT_tokenizer_2.0\\\\added_tokens.json',\n",
       " 'SWT_tokenizer_2.0\\\\tokenizer.json')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "model.save_pretrained('SWT_ner_model_2.0')\n",
    "tokenizer.save_pretrained('SWT_tokenizer_2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b097dd423b7644a2877af945ba2f436a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: condition seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: design seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_D seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_A seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_A seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_D seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: N_B seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: group_B seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\Gbadamosi\\Documents\\Nerd Corner\\Master in ds and AI\\MSC project\\workspace\\personal_workspace\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.01858198456466198,\n",
       " 'eval_precision': 0.7575083426028921,\n",
       " 'eval_recall': 0.791860465116279,\n",
       " 'eval_f1': 0.7743035815804433,\n",
       " 'eval_accuracy': 0.9956355760711434,\n",
       " 'eval_runtime': 36.4534,\n",
       " 'eval_samples_per_second': 5.871,\n",
       " 'eval_steps_per_second': 1.481,\n",
       " 'epoch': 4.99}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset= tokenized_dataset['test'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We aimed to determine prospectively whether rivastigmine, an inhibitor of acetylcholinesterase and butyrylcholinesterase, provided benefits in patients with and without visual hallucinations in a population with dementia associated with Parkinson's disease (PDD)\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"We aimed to determine prospectively whether rivastigmine, an inhibitor of acetylcholinesterase and butyrylcholinesterase, provided benefits in patients with and without visual hallucinations in a population with dementia associated with Parkinson's disease (PDD)\"\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using checkpoint test_swt_2.0\\checkpoint-1200\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = trainer.state.best_model_checkpoint # or save model in disk and load it later\n",
    "print(f\"using checkpoint {model_checkpoint}\")\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "token_classifier = pipeline(\"token-classification\", model=model_checkpoint, aggregation_strategy=\"first\")\n",
    "# token_classifier.tokenizer.model_max_length = model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'condition', 'score': 0.4898637, 'word': 'a', 'start': 194, 'end': 195}]\n"
     ]
    }
   ],
   "source": [
    "res = token_classifier(sentence, aggregation_strategy=\"first\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
